# Commandes syst√®me utiles pour la programmation MPI

Guide complet des commandes pour analyser votre syst√®me, optimiser vos programmes MPI et d√©boguer vos applications parall√®les.

## Table des mati√®res

- [Analyser votre CPU](#analyser-votre-cpu)
- [Commandes MPI essentielles](#commandes-mpi-essentielles)
- [Monitoring et performance](#monitoring-et-performance)
- [Compilation et debugging](#compilation-et-debugging)
- [Gestion de la m√©moire](#gestion-de-la-m√©moire)
- [Scripts utiles](#scripts-utiles)

---

## Analyser votre CPU

### `lscpu` - Informations compl√®tes sur le CPU

```bash
lscpu
```

**Sortie typique** :
```
Architecture:            x86_64
  CPU op-mode(s):        32-bit, 64-bit
  Address sizes:         48 bits physical, 48 bits virtual
  Byte Order:            Little Endian
CPU(s):                  8                    ‚Üê Nombre total de CPUs logiques
  On-line CPU(s) list:   0-7
Vendor ID:               GenuineIntel
  Model name:            Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz
    CPU family:          6
    Model:               165
    Thread(s) per core:  2                    ‚Üê Hyperthreading activ√©
    Core(s) per socket:  4                    ‚Üê 4 c≈ìurs physiques
    Socket(s):           1
```

**Informations cl√©s pour MPI** :
- **CPU(s)** : Nombre de processeurs logiques (8 dans cet exemple)
- **Core(s) per socket** : C≈ìurs physiques (4 ici)
- **Thread(s) per core** : Si = 2, hyperthreading activ√©
- **Socket(s)** : Nombre de processeurs physiques

**Recommandation pour MPI** :
```bash
# Nombre optimal de processus MPI = nombre de c≈ìurs physiques
# Dans l'exemple ci-dessus : 4 c≈ìurs √ó 1 socket = 4 processus

mpirun -np 4 ./mon_programme
```

### Commandes alternatives

```bash
# Nombre de CPUs logiques
nproc
# Sortie: 8

# Nombre de c≈ìurs physiques
nproc --all
lscpu | grep "^Core(s) per socket" | awk '{print $4}'

# Informations d√©taill√©es sur chaque CPU
cat /proc/cpuinfo

# Filtrer pour voir seulement le mod√®le
cat /proc/cpuinfo | grep "model name" | uniq

# Architecture du processeur
uname -m
# Sortie: x86_64
```

---

## Commandes MPI essentielles

### V√©rifier l'installation MPI

```bash
# Version du compilateur MPI
mpicc --version
mpic++ --version
mpif90 --version  # Pour Fortran

# Version de MPI
mpirun --version
# ou
ompi_info | grep "Open MPI"

# Localisation des binaires
which mpicc
which mpirun

# Informations compl√®tes sur Open MPI
ompi_info
```

### Compiler avec options de d√©bogage

```bash
# Compilation standard
mpicc programme.c -o programme

# Avec optimisation
mpicc -O3 programme.c -o programme

# Avec debugging
mpicc -g -Wall programme.c -o programme

# Avec biblioth√®que math√©matique
mpicc programme.c -o programme -lm

# Verbose (voir toutes les √©tapes)
mpicc -v programme.c -o programme

# Afficher les flags de compilation utilis√©s
mpicc --showme
# Sortie typique: gcc -I/usr/lib/x86_64-linux-gnu/openmpi/include ...
```

### Ex√©cuter des programmes MPI

```bash
# Ex√©cution basique avec 4 processus
mpirun -np 4 ./programme

# Sp√©cifier les slots par n≈ìud
mpirun -np 4 --map-by core ./programme

# Verbose (voir ce qui se passe)
mpirun -v -np 4 ./programme

# Afficher le binding (o√π sont les processus)
mpirun -np 4 --report-bindings ./programme

# Limiter √† un socket sp√©cifique
mpirun -np 4 --bind-to core --map-by socket ./programme

# Sur plusieurs machines (cluster)
mpirun -np 8 -hostfile machines.txt ./programme

# Exemple de fichier machines.txt:
# node1 slots=4
# node2 slots=4

# Avec timeout (en secondes)
timeout 30 mpirun -np 4 ./programme

# Rediriger la sortie
mpirun -np 4 ./programme > output.txt 2>&1
```

### Options avanc√©es de mpirun

```bash
# D√©sactiver les messages de warning
mpirun --mca btl_base_warn_component_unused 0 -np 4 ./programme

# Utiliser uniquement la m√©moire partag√©e (1 machine)
mpirun --mca btl self,sm -np 4 ./programme

# Afficher les variables d'environnement
mpirun -np 4 -x MY_VAR=value ./programme

# Lancer avec un profiler
mpirun -np 4 valgrind --leak-check=full ./programme

# D√©finir la politique de placement
mpirun -np 4 --map-by core:PE=2 ./programme
```

---

## Monitoring et performance

### `htop` - Monitoring interactif

```bash
# Installer htop si n√©cessaire
sudo apt-get install htop

# Lancer htop
htop

# Dans htop pendant l'ex√©cution MPI:
# - F2 : Configuration
# - F4 : Filtrer par nom de processus
# - F5 : Vue arborescente
# - F9 : Tuer un processus
# - F10 : Quitter
```

**Astuce** : Lancez htop dans un terminal, votre programme MPI dans un autre

```bash
# Terminal 1
htop

# Terminal 2
mpirun -np 4 ./programme
```

### `top` - Monitoring basique

```bash
# Vue classique
top

# Trier par CPU (shift + P)
# Trier par m√©moire (shift + M)
# Filtrer par utilisateur (u)
# Rafra√Æchir (espace)

# Avec mise √† jour automatique
watch -n 1 'ps aux | grep "mon_programme"'
```

### `time` - Mesurer le temps d'ex√©cution

```bash
# Temps basique
time mpirun -np 4 ./programme

# Sortie:
# real    0m2.345s    ‚Üê Temps total (horloge murale)
# user    0m8.123s    ‚Üê Temps CPU total
# sys     0m0.234s    ‚Üê Temps syst√®me

# Temps d√©taill√©
/usr/bin/time -v mpirun -np 4 ./programme
# Affiche: CPU%, m√©moire max, page faults, etc.
```

### Mesurer la performance CPU

```bash
# Temp√©rature CPU (n√©cessite lm-sensors)
sudo apt-get install lm-sensors
sensors

# Fr√©quence des CPUs
watch -n 1 'cat /proc/cpuinfo | grep MHz'

# Charge du syst√®me
uptime
# Sortie: load average: 1.23, 0.89, 0.45
# Les 3 nombres = charge sur 1min, 5min, 15min

# Utilisation CPU en temps r√©el
mpstat 1 5
# Affiche les stats CPU toutes les 1 seconde, 5 fois
```

### `perf` - Profiling avanc√©

```bash
# Installer perf
sudo apt-get install linux-tools-generic

# Profiler un programme MPI
perf stat mpirun -np 4 ./programme

# Sortie typique:
#  Performance counter stats for 'mpirun -np 4 ./programme':
#           2345.67 msec task-clock
#              1234      context-switches
#              5678      cpu-migrations
#         12345678      cycles
#          8901234      instructions
#             0.67      IPC (instructions per cycle)

# Enregistrer le profiling
perf record mpirun -np 4 ./programme
perf report

# Analyser le cache
perf stat -e cache-references,cache-misses mpirun -np 4 ./programme
```

---

## Compilation et debugging

### Options de compilation utiles

```bash
# Debug complet
mpicc -g -O0 -Wall -Wextra programme.c -o programme

# Avec sanitizers (d√©tection d'erreurs m√©moire)
mpicc -g -fsanitize=address programme.c -o programme

# D√©tection de race conditions
mpicc -g -fsanitize=thread programme.c -o programme

# G√©n√©rer des warnings utiles
mpicc -Wall -Wextra -Wpedantic -Wconversion programme.c -o programme

# V√©rifier la syntaxe sans compiler
mpicc -fsyntax-only programme.c

# Pr√©processeur uniquement
mpicc -E programme.c > programme.i
```

### Debugging avec GDB

```bash
# Compiler avec symboles de debug
mpicc -g programme.c -o programme

# D√©boguer un seul processus
gdb ./programme

# D√©boguer MPI (m√©thode 1: attacher manuellement)
# Terminal 1:
mpirun -np 4 xterm -e gdb ./programme

# D√©boguer MPI (m√©thode 2: avec script)
cat > debug_mpi.sh << 'EOF'
#!/bin/bash
xterm -e gdb -ex run --args ./programme &
EOF
chmod +x debug_mpi.sh
mpirun -np 4 ./debug_mpi.sh

# Commandes GDB utiles:
# (gdb) run                    # Ex√©cuter
# (gdb) break main             # Point d'arr√™t
# (gdb) break 42               # Point d'arr√™t ligne 42
# (gdb) continue               # Continuer
# (gdb) step                   # Pas √† pas (entre dans les fonctions)
# (gdb) next                   # Pas √† pas (saute les fonctions)
# (gdb) print variable         # Afficher une variable
# (gdb) backtrace              # Pile d'appels
# (gdb) quit                   # Quitter
```

### Valgrind - D√©tection de fuites m√©moire

```bash
# Installation
sudo apt-get install valgrind

# V√©rification basique
mpirun -np 2 valgrind --leak-check=full ./programme

# V√©rification d√©taill√©e
mpirun -np 2 valgrind --leak-check=full --show-leak-kinds=all \
  --track-origins=yes --verbose ./programme

# Sauvegarder dans un fichier
mpirun -np 2 valgrind --leak-check=full \
  --log-file=valgrind-%p.log ./programme
# Cr√©e valgrind-PID.log pour chaque processus

# D√©tecter les race conditions (plus lent)
mpirun -np 2 valgrind --tool=helgrind ./programme
```

### V√©rifier les liens et d√©pendances

```bash
# Voir les biblioth√®ques li√©es
ldd ./programme
# Sortie:
# libmpi.so.40 => /usr/lib/x86_64-linux-gnu/libmpi.so.40
# libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6

# V√©rifier les symboles MPI
nm ./programme | grep MPI_

# Voir la taille des sections
size ./programme
```

---

## Gestion de la m√©moire

### Informations m√©moire syst√®me

```bash
# M√©moire totale disponible
free -h

# Sortie:
#               total        used        free      shared  buff/cache   available
# Mem:           15Gi       3.2Gi       8.1Gi       200Mi       4.0Gi        11Gi
# Swap:         2.0Gi          0B       2.0Gi

# Mises √† jour continues
watch -n 1 free -h

# D√©tails sur la m√©moire
cat /proc/meminfo

# M√©moire par processus
ps aux --sort=-%mem | head -10

# M√©moire d'un processus sp√©cifique
ps -o pid,user,%mem,command -p <PID>
```

### Limites de ressources

```bash
# Voir les limites actuelles
ulimit -a

# Augmenter la taille de pile (stack)
ulimit -s unlimited

# Limiter la m√©moire (en KB)
ulimit -m 1000000

# Pour un programme MPI
ulimit -s unlimited && mpirun -np 4 ./programme

# D√©finir les limites dans un script
cat > run_with_limits.sh << 'EOF'
#!/bin/bash
ulimit -s unlimited
ulimit -m 4000000
mpirun -np 4 ./programme
EOF
```

### Surveiller l'utilisation m√©moire d'un programme

```bash
# Pendant l'ex√©cution
# Terminal 1:
mpirun -np 4 ./programme &
PID=$!

# Terminal 2:
watch -n 1 "ps -o pid,vsz,rss,comm -p $PID"

# Avec un script automatique
cat > monitor_memory.sh << 'EOF'
#!/bin/bash
PROG=$1
LOGFILE="memory_usage.log"

mpirun -np 4 ./$PROG &
PID=$!

echo "Time,VSZ,RSS" > $LOGFILE
while kill -0 $PID 2>/dev/null; do
    ps -o vsz=,rss= -p $PID | \
    awk -v t="$(date +%s)" '{print t","$1","$2}' >> $LOGFILE
    sleep 0.1
done
EOF
chmod +x monitor_memory.sh
./monitor_memory.sh programme
```

---

## Scripts utiles

### Script de benchmark automatique

```bash
cat > benchmark_mpi.sh << 'EOF'
#!/bin/bash

PROGRAMME=$1
MAX_PROCS=$(nproc)

echo "Benchmark MPI pour $PROGRAMME"
echo "Nombre de c≈ìurs: $MAX_PROCS"
echo "================================"
echo ""

for np in 1 2 4 8 16; do
    if [ $np -le $MAX_PROCS ]; then
        echo "Test avec $np processus:"
        /usr/bin/time -f "Temps r√©el: %E\nCPU: %P\nM√©moire max: %M KB" \
            mpirun -np $np ./$PROGRAMME
        echo "---"
    fi
done
EOF

chmod +x benchmark_mpi.sh
./benchmark_mpi.sh mon_programme
```

### Script de v√©rification de l'environnement

```bash
cat > check_mpi_env.sh << 'EOF'
#!/bin/bash

echo "=== V√©rification de l'environnement MPI ==="
echo ""

# V√©rifier MPI
echo "1. Installation MPI:"
if command -v mpicc &> /dev/null; then
    echo "   ‚úì mpicc trouv√©: $(which mpicc)"
    mpicc --version | head -1
else
    echo "   ‚úó mpicc non trouv√©"
fi

if command -v mpirun &> /dev/null; then
    echo "   ‚úì mpirun trouv√©: $(which mpirun)"
    mpirun --version | head -1
else
    echo "   ‚úó mpirun non trouv√©"
fi

echo ""
echo "2. Informations CPU:"
echo "   - C≈ìurs logiques: $(nproc)"
echo "   - Architecture: $(uname -m)"
CORES=$(lscpu | grep "^Core(s) per socket" | awk '{print $4}')
SOCKETS=$(lscpu | grep "^Socket(s)" | awk '{print $2}')
echo "   - C≈ìurs physiques: $((CORES * SOCKETS))"

echo ""
echo "3. M√©moire disponible:"
free -h | grep "Mem:" | awk '{print "   - Total: "$2", Disponible: "$7}'

echo ""
echo "4. Test MPI basique:"
cat > test_mpi_tmp.c << 'EOFC'
#include <mpi.h>
#include <stdio.h>
int main() {
    MPI_Init(NULL, NULL);
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    printf("Process %d: OK\n", rank);
    MPI_Finalize();
    return 0;
}
EOFC

if mpicc test_mpi_tmp.c -o test_mpi_tmp 2>/dev/null; then
    echo "   ‚úì Compilation r√©ussie"
    if mpirun -np 2 ./test_mpi_tmp &>/dev/null; then
        echo "   ‚úì Ex√©cution r√©ussie"
    else
        echo "   ‚úó Erreur d'ex√©cution"
    fi
    rm -f test_mpi_tmp test_mpi_tmp.c
else
    echo "   ‚úó Erreur de compilation"
fi

echo ""
echo "=== V√©rification termin√©e ==="
EOF

chmod +x check_mpi_env.sh
./check_mpi_env.sh
```

### Script de profiling complet

```bash
cat > profile_mpi.sh << 'EOF'
#!/bin/bash

PROGRAMME=$1
NP=${2:-4}

echo "Profiling de $PROGRAMME avec $NP processus"
echo "==========================================="

# 1. Temps d'ex√©cution
echo "1. Temps d'ex√©cution:"
/usr/bin/time -v mpirun -np $NP ./$PROGRAMME 2>&1 | \
    grep -E "Elapsed|Maximum resident|Percent of CPU"

# 2. Statistiques CPU
echo ""
echo "2. Statistiques CPU:"
perf stat mpirun -np $NP ./$PROGRAMME 2>&1 | \
    grep -E "seconds|instructions|cycles"

# 3. Utilisation m√©moire
echo ""
echo "3. Pic d'utilisation m√©moire par processus:"
mpirun -np $NP valgrind --tool=massif --massif-out-file=massif.%p ./$PROGRAMME \
    2>/dev/null
for f in massif.*; do
    grep mem_heap_B $f | sed -e 's/mem_heap_B=\(.*\)/\1/' | \
    sort -g | tail -1 | awk '{print "   "$1/1024/1024" MB"}'
done
rm -f massif.*

echo ""
echo "Profiling termin√©!"
EOF

chmod +x profile_mpi.sh
./profile_mpi.sh mon_programme 4
```

### G√©n√©rer un rapport de performance

```bash
cat > generate_report.sh << 'EOF'
#!/bin/bash

PROGRAMME=$1
OUTPUT="performance_report.txt"

{
    echo "RAPPORT DE PERFORMANCE"
    echo "======================"
    echo "Programme: $PROGRAMME"
    echo "Date: $(date)"
    echo "Machine: $(hostname)"
    echo ""
    
    echo "CONFIGURATION SYST√àME"
    echo "---------------------"
    lscpu | grep -E "Model name|CPU\(s\)|Core|Thread"
    echo ""
    free -h
    echo ""
    
    echo "BENCHMARKS"
    echo "----------"
    for np in 1 2 4 8; do
        if [ $np -le $(nproc) ]; then
            echo "Avec $np processus:"
            time mpirun -np $np ./$PROGRAMME 2>&1 | grep real
        fi
    done
    
} > $OUTPUT

echo "Rapport g√©n√©r√©: $OUTPUT"
EOF

chmod +x generate_report.sh
./generate_report.sh mon_programme
```

---

## Commandes de comparaison de performance

### Comparer diff√©rentes configurations

```bash
# Script de comparaison
cat > compare_configs.sh << 'EOF'
#!/bin/bash

PROG=$1

echo "Config,Processus,Temps(s),Speedup"

# Temps de r√©f√©rence (s√©quentiel)
T1=$(mpirun -np 1 ./$PROG 2>&1 | grep -oP '(?<=real\t).*' | \
     sed 's/m/*60+/; s/s//; s/^/scale=3;/' | bc)

# Tests parall√®les
for np in 2 4 8 16; do
    if [ $np -le $(nproc) ]; then
        T=$(mpirun -np $np ./$PROG 2>&1 | grep -oP '(?<=real\t).*' | \
            sed 's/m/*60+/; s/s//; s/^/scale=3;/' | bc)
        SPEEDUP=$(echo "scale=2; $T1 / $T" | bc)
        echo "Parallel,$np,$T,$SPEEDUP"
    fi
done
EOF

chmod +x compare_configs.sh
./compare_configs.sh mon_programme | column -t -s,
```

---

## Commandes de diagnostic rapide

```bash
# Tout-en-un: statut syst√®me pour MPI
alias mpicheck='echo "=== CPU ==="; lscpu | grep -E "CPU\(s\)|Core"; \
                echo "=== M√©moire ==="; free -h | grep Mem; \
                echo "=== MPI ==="; mpirun --version | head -1'

# Voir les processus MPI actifs
alias mpiprocs='ps aux | grep -E "mpirun|[m]pi"'

# Tuer tous les processus MPI
alias mpikill='pkill -9 -f mpirun; pkill -9 -f "\.\/.*"'

# Nettoyage rapide
alias mpiclean='rm -f *.o *.out core.* massif.* valgrind-*.log'
```

---

## Fichier .bashrc utile

Ajoutez ces lignes √† votre `~/.bashrc` :

```bash
# Ajouter √† ~/.bashrc

# Alias MPI
alias mpic='mpicc -Wall -O3'
alias mpicd='mpicc -g -Wall -O0'
alias mpir='mpirun -np 4'

# Variables d'environnement
export OMPI_MCA_btl_base_warn_component_unused=0

# Fonction pour compiler et ex√©cuter
mpirun_quick() {
    mpicc $1 -o ${1%.c} && mpirun -np ${2:-4} ./${1%.c}
}

# Fonction pour profiler rapidement
mpiprof() {
    perf stat mpirun -np ${2:-4} ./$1
}

# Recharger: source ~/.bashrc
```

---

## R√©solution de probl√®mes courants

### "Cannot find lscpu"

```bash
# Installer les outils syst√®me
sudo apt-get install util-linux
```

### "mpirun not found"

```bash
# V√©rifier l'installation
dpkg -l | grep -i openmpi

# R√©installer si n√©cessaire
sudo apt-get install --reinstall openmpi-bin
```

### Erreur "btl_tcp_if_include"

```bash
# Ajouter √† votre commande:
mpirun --mca btl_tcp_if_include lo -np 4 ./programme
```

### Programme bloqu√©/deadlock

```bash
# Envoyer un signal pour voir o√π il est bloqu√©
kill -QUIT <PID>

# Ou utiliser timeout
timeout 10 mpirun -np 4 ./programme

# Debug avec stack trace
mpirun -np 4 gdb -batch -ex "run" -ex "thread apply all bt" ./programme
```

---

## üìö R√©sum√© des commandes essentielles

```bash
# Configuration syst√®me
lscpu                              # Info CPU
nproc                              # Nombre de c≈ìurs
free -h                            # M√©moire disponible
uname -a                           # Info syst√®me

# MPI
mpicc --version                    # Version compilateur
mpirun --version                   # Version runtime
ompi_info                          # Info d√©taill√©es OpenMPI

# Compilation
mpicc -Wall -O3 prog.c -o prog    # Optimis√©
mpicc -g prog.c -o prog           # Debug

# Ex√©cution
mpirun -np 4 ./prog               # Standard
mpirun -np 4 --report-bindings    # Voir placement
mpirun -np 4 -v                   # Verbose

# Monitoring
htop                              # Interactif
top                               # Classique
time mpirun -np 4 ./prog         # Mesurer temps
perf stat mpirun -np 4 ./prog    # Statistiques CPU

# Debug
gdb ./prog                        # Debugger
valgrind ./prog                   # Fuites m√©moire
mpirun -np 2 valgrind ./prog     # MPI + valgrind

# Performance
perf record mpirun -np 4 ./prog  # Enregistrer profil
perf report                       # Analyser profil
```
